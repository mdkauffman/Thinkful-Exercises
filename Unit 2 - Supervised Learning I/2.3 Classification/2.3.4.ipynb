{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab and process the raw data.\n",
    "imdb_raw = pd.read_csv('imdb_labelled.txt', delimiter= '\\t', header=None)\n",
    "imdb_raw.columns = ['text', 'positive y/n']\n",
    "\n",
    "amazon_raw = pd.read_csv('amazon_cells_labelled.txt', delimiter= '\\t', header=None)\n",
    "amazon_raw.columns = ['text', 'positive y/n']\n",
    "\n",
    "yelp_raw = pd.read_csv('yelp_labelled.txt', delimiter= '\\t', header=None)\n",
    "yelp_raw.columns = ['text', 'positive y/n']\n",
    "\n",
    "# joining the dataframes together\n",
    "#alltext_raw = pd.concat([yelp_raw, amazon_raw, imdb_raw])\n",
    "alltext_raw = amazon_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1\n",
    "alltext_raw1 = alltext_raw\n",
    "\n",
    "pro_keywords1 = ['great', 'super', 'excellent', 'sturdy', 'satisfied', 'best', 'good purchase', 'happy', 'good', 'nice', 'love', 'nice', 'comfortable', 'tremendous', 'forever', 'awesome', 'fast', 'decent', 'comfortable', 'flawless', 'helpful', 'wise', 'low price', 'easier', 'well finished', 'very well', 'promptly','amazed','well','easy','highly','again','good quality','high quality','smooth','pleasant','ly recommend', 'i like', 'y like']\n",
    "\n",
    "for key in pro_keywords1:\n",
    "    alltext_raw1[str(key)] = alltext_raw1.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )\n",
    "\n",
    "con_keywords1 = ['not happy', 'waste of', 'beware', 'disappoint', 'bad', 'worst', 'flimsy', 'junk', 'avoid', 'poor', 't buy', 't recommend', 'return', 'lacking', 'unhappy', 'rip off', 'a problem', 'the problem', 'sucks', 'dead', 'break','mistake','broke','warning','dying','died','difficult','not good','uncomfortable','ugly','refund','unfortunate','defective','crap','cumbersome','hate','worthless','t work','complain','horrible','useless', 't like']\n",
    "\n",
    "for key in con_keywords1:\n",
    "    alltext_raw1[str(key)] = alltext_raw1.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2 - Using alltext_raw.sum() to calculate the total hits for each feature, and removing the lowest; cutoff for removal was < 8 in the pro, and < 7 in the con.\n",
    "alltext_raw2 = alltext_raw\n",
    "\n",
    "pro_keywords2 = ['great', 'excellent', 'best', 'happy', 'good', 'nice', 'love', 'nice', 'comfortable', 'very well','well','easy','highly','again','good quality','ly recommend']\n",
    "for key in pro_keywords2:\n",
    "    alltext_raw2[str(key)] = alltext_raw2.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )\n",
    "\n",
    "con_keywords2 = ['disappoint', 'bad', 'worst',  'junk', 'poor', 't buy', 'return', 'break','broke','t work','horrible','useless']\n",
    "\n",
    "for key in con_keywords2:\n",
    "    alltext_raw2[str(key)] = alltext_raw2.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 3 - Opposite design as version 2, removing the most frequent features (anything greater than 10 hits) to see how much of an effect it has.\n",
    "alltext_raw3 = alltext_raw\n",
    "\n",
    "pro_keywords3 = ['super', 'sturdy', 'satisfied', 'good purchase', 'tremendous', 'forever', 'awesome', 'fast', 'decent', 'flawless', 'helpful', 'wise', 'low price', 'easier', 'well finished', 'very well', 'promptly','amazed','highly','good quality','high quality','smooth','pleasant','i like', 'y like']\n",
    "\n",
    "for key in pro_keywords2:\n",
    "    alltext_raw3[str(key)] = alltext_raw3.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )\n",
    "\n",
    "con_keywords3 = ['not happy', 'waste of', 'beware', 't recommend', 'return', 'lacking', 'unhappy', 'rip off', 'a problem', 'the problem', 'sucks', 'dead', 'break','mistake','broke','warning','dying','died','difficult','not good','uncomfortable','ugly','refund','unfortunate','defective','crap','cumbersome','hate','worthless','complain','horrible','useless', 't like', 'flimsy', 'junk', 'avoid']\n",
    "\n",
    "for key in con_keywords3:\n",
    "    alltext_raw3[str(key)] = alltext_raw3.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 4 - using only pro keywords\n",
    "alltext_raw4 = alltext_raw\n",
    "\n",
    "pro_keywords4 = ['great', 'super', 'excellent', 'sturdy', 'satisfied', 'best', 'good purchase', 'happy', 'good', 'nice', 'love', 'nice', 'comfortable', 'tremendous', 'forever', 'awesome', 'fast', 'decent', 'comfortable', 'flawless', 'helpful', 'wise', 'low price', 'easier', 'well finished', 'very well', 'promptly','amazed','well','easy','highly','again','good quality','high quality','smooth','pleasant','ly recommend', 'i like', 'y like']\n",
    "\n",
    "for key in pro_keywords4:\n",
    "    alltext_raw4[str(key)] = alltext_raw4.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )\n",
    "\n",
    "con_keywords4 = []\n",
    "\n",
    "for key in con_keywords4:\n",
    "    alltext_raw4[str(key)] = alltext_raw4.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 5 - using only con keywords\n",
    "alltext_raw5 = alltext_raw\n",
    "\n",
    "pro_keywords5 = []\n",
    "\n",
    "for key in pro_keywords5:\n",
    "    alltext_raw5[str(key)] = alltext_raw5.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )\n",
    "\n",
    "con_keywords5 = ['not happy', 'waste of', 'beware', 'disappoint', 'bad', 'worst', 'flimsy', 'junk', 'avoid', 'poor', 't buy', 't recommend', 'return', 'lacking', 'unhappy', 'rip off', 'a problem', 'the problem', 'sucks', 'dead', 'break','mistake','broke','warning','dying','died','difficult','not good','uncomfortable','ugly','refund','unfortunate','defective','crap','cumbersome','hate','worthless','t work','complain','horrible','useless', 't like']\n",
    "\n",
    "for key in con_keywords5:\n",
    "    alltext_raw5[str(key)] = alltext_raw5.text.str.contains(\n",
    "        str(key),\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERSION 1\n",
      "Number of mislabeled points out of a total 1000 points : 201\n",
      " \n",
      "Confusion matrix: \n",
      "[[471  29]\n",
      " [172 328]]\n",
      " \n",
      "Holdout:\n",
      "With 20% Holdout: 0.77\n",
      "Testing on Sample: 0.799\n",
      " \n",
      "Cross Validation: [0.84 0.75 0.83 0.76 0.79 0.75 0.76 0.76 0.8  0.74]\n"
     ]
    }
   ],
   "source": [
    "test = alltext_raw1\n",
    "\n",
    "data = test[\n",
    "    pro_keywords1\n",
    "    + \n",
    "    con_keywords1\n",
    "                  ]\n",
    "target = test['positive y/n']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print('VERSION 1')\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))\n",
    "print(' ')\n",
    "\n",
    "# confusion matrix\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix(target, y_pred))\n",
    "print(' ')\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('Holdout:')\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))\n",
    "print(' ')\n",
    "\n",
    "# Cross Validation\n",
    "print('Cross Validation: ' + str(cross_val_score(bnb, data, target, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERSION 2\n",
      "Number of mislabeled points out of a total 1000 points : 245\n",
      " \n",
      "Confusion matrix: \n",
      "[[462  38]\n",
      " [207 293]]\n",
      " \n",
      "Holdout:\n",
      "With 20% Holdout: 0.73\n",
      "Testing on Sample: 0.755\n",
      " \n",
      "Cross Validation: [0.84 0.73 0.81 0.74 0.75 0.69 0.74 0.74 0.77 0.71]\n"
     ]
    }
   ],
   "source": [
    "test = alltext_raw2\n",
    "\n",
    "data = test[\n",
    "    pro_keywords2 \n",
    "    + \n",
    "    con_keywords2\n",
    "                  ]\n",
    "target = test['positive y/n']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print('VERSION 2')\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))\n",
    "print(' ')\n",
    "\n",
    "# confusion matrix\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix(target, y_pred))\n",
    "print(' ')\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('Holdout:')\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))\n",
    "print(' ')\n",
    "\n",
    "# Cross Validation\n",
    "print('Cross Validation: ' + str(cross_val_score(bnb, data, target, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERSION 3\n",
      "Number of mislabeled points out of a total 1000 points : 373\n",
      " \n",
      "Confusion matrix: \n",
      "[[133 367]\n",
      " [  6 494]]\n",
      " \n",
      "Holdout:\n",
      "With 20% Holdout: 0.605\n",
      "Testing on Sample: 0.627\n",
      " \n",
      "Cross Validation: [0.58 0.56 0.63 0.65 0.72 0.63 0.59 0.6  0.64 0.6 ]\n"
     ]
    }
   ],
   "source": [
    "test = alltext_raw3\n",
    "\n",
    "data = test[\n",
    "    pro_keywords3 \n",
    "    + \n",
    "    con_keywords3\n",
    "                  ]\n",
    "target = test['positive y/n']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print('VERSION 3')\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))\n",
    "print(' ')\n",
    "\n",
    "# confusion matrix\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix(target, y_pred))\n",
    "print(' ')\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('Holdout:')\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))\n",
    "print(' ')\n",
    "\n",
    "# Cross Validation\n",
    "print('Cross Validation: ' + str(cross_val_score(bnb, data, target, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERSION 4\n",
      "Number of mislabeled points out of a total 1000 points : 227\n",
      " \n",
      "Confusion matrix: \n",
      "[[455  45]\n",
      " [182 318]]\n",
      " \n",
      "Holdout:\n",
      "With 20% Holdout: 0.75\n",
      "Testing on Sample: 0.773\n",
      " \n",
      "Cross Validation: [0.85 0.73 0.81 0.74 0.77 0.73 0.7  0.75 0.78 0.7 ]\n"
     ]
    }
   ],
   "source": [
    "test = alltext_raw4\n",
    "\n",
    "data = test[\n",
    "    pro_keywords4 \n",
    "    + \n",
    "    con_keywords4\n",
    "                  ]\n",
    "target = test['positive y/n']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print('VERSION 4')\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))\n",
    "print(' ')\n",
    "\n",
    "# confusion matrix\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix(target, y_pred))\n",
    "print(' ')\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('Holdout:')\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))\n",
    "print(' ')\n",
    "\n",
    "# Cross Validation\n",
    "print('Cross Validation: ' + str(cross_val_score(bnb, data, target, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERSION 5\n",
      "Number of mislabeled points out of a total 1000 points : 309\n",
      " \n",
      "Confusion matrix: \n",
      "[[195 305]\n",
      " [  4 496]]\n",
      " \n",
      "Holdout:\n",
      "With 20% Holdout: 0.695\n",
      "Testing on Sample: 0.691\n",
      " \n",
      "Cross Validation: [0.65 0.64 0.7  0.73 0.77 0.7  0.67 0.63 0.72 0.66]\n"
     ]
    }
   ],
   "source": [
    "test = alltext_raw5\n",
    "\n",
    "data = test[\n",
    "    pro_keywords5 \n",
    "    + \n",
    "    con_keywords5\n",
    "                  ]\n",
    "target = test['positive y/n']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print('VERSION 5')\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))\n",
    "print(' ')\n",
    "\n",
    "# confusion matrix\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix(target, y_pred))\n",
    "print(' ')\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('Holdout:')\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))\n",
    "print(' ')\n",
    "\n",
    "# Cross Validation\n",
    "print('Cross Validation: ' + str(cross_val_score(bnb, data, target, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Do any of your classifiers seem to overfit?_\n",
    "\n",
    "Versions 3 & 5 seem to indicate that the pro-keyword classifiers with high frequencies are causing overfitting and inaccuracies by pushing up the incorrect labeling of negative reviews as positive, as shown by the single-digit inaccuracy rates in the confusion matrices for V3 & V5.  \n",
    "\n",
    "No other significant variances in results beyond expectations that would indicate overfitting due to other factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Which seem to perform the best? Why?_\n",
    "\n",
    "V1 is, unsurprisingly, the best performer, due primarily to the fact that I over-engineered it in my first attempt, and then performed operations on it to see how things would break when I changed them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Which features seemed to be most impactful to performance?_\n",
    "\n",
    "High-frequency features, those that appeared in the most reviews, had the most significant positive impact on the model, albeit with some shifting of errors from incorrectly labeled positive reviews to incorrectly labeled negative reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
