{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "import math\n",
    "import warnings\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"scipy\",\n",
    "    message=\"^internal gelsd\"\n",
    ")\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import pydotplus\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataset\n",
    "base_fraud_data = pd.read_csv('creditcard.csv').dropna()\n",
    "\n",
    "# Sample smaller chunks to speed up testing models\n",
    "half_data = base_fraud_data.sample(frac=.5, random_state=2)\n",
    "quarter_data = base_fraud_data.sample(frac=.25, random_state=2)\n",
    "tenth_data = base_fraud_data.sample(frac=.1, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a report function that can be used for any model\n",
    "\n",
    "def accuracy_report(testing_X, testing_Y, model):\n",
    "    predictions = model.predict(testing_X)\n",
    "    print('Model score:')\n",
    "    print(model.score(testing_X, testing_Y))\n",
    "    print(\" \")\n",
    "    print('Confusion Matrix (UL: True Negative, UR: False Positive, BL: False Negative, BR: True Positive)')\n",
    "    print(confusion_matrix(testing_Y.values, predictions))\n",
    "    print(\" \")\n",
    "    print('Accuracy:')\n",
    "    print(accuracy_score(testing_Y.values, predictions))\n",
    "    print(\" \")\n",
    "    print('Recall/Sensitivity (% of late arrivals predicted):')\n",
    "    print(recall_score(testing_Y.values, predictions))\n",
    "    print(\" \")\n",
    "    print('Precision (% of on-time arrivals predicted accurately):')\n",
    "    print(precision_score(testing_Y.values, predictions))\n",
    "    print(\" \")\n",
    "    auc = roc_auc_score(testing_Y.values, predictions)\n",
    "    print('AUC score:%.3f'% auc)\n",
    "    print(\" \")\n",
    "    print('Model cross-valuation:')\n",
    "    print(sklearn.model_selection.cross_val_score(model, testing_X, testing_Y, cv = 5))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "working_df = base_fraud_data\n",
    "training_fraction = .8\n",
    "\n",
    "training_X = working_df.sample(frac=training_fraction, random_state=10)\n",
    "testing_X = working_df.drop(training_X.index)\n",
    "\n",
    "# separate the Class feature out into Y datasets\n",
    "training_Y = training_X['Class']\n",
    "testing_Y = testing_X['Class']\n",
    "\n",
    "# dropping the Class feature from the X datasets so that the model isn't able to cheat\n",
    "training_X.drop('Class', axis=1, inplace=True)\n",
    "testing_X.drop('Class', axis=1, inplace=True)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168367</th>\n",
       "      <td>119191.000</td>\n",
       "      <td>2.052</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-1.741</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.338</td>\n",
       "      <td>-0.827</td>\n",
       "      <td>0.335</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>0.762</td>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.569</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>8.730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time    V1     V2     V3    V4    V5     V6    V7     V8    V9  \\\n",
       "168367 119191.000 2.052 -0.133 -1.741 0.278 0.338 -0.827 0.335 -0.227 0.268   \n",
       "\n",
       "         V10   V11   V12    V13   V14    V15    V16    V17    V18   V19  \\\n",
       "168367 0.294 0.428 0.504 -0.989 0.762 -0.985 -0.296 -0.337 -0.232 0.544   \n",
       "\n",
       "          V20    V21   V22   V23    V24   V25   V26    V27    V28  Amount  \n",
       "168367 -0.269 -0.007 0.121 0.038 -0.356 0.148 0.569 -0.104 -0.092   8.730  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN recommended parameters:\n",
      "{'algorithm': 'ball_tree', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Gridsearch CV for the KNN algorithm\n",
    "\n",
    "neighbors = KNeighborsClassifier(weights='uniform', n_neighbors=6, algorithm= 'ball_tree')\n",
    "\n",
    "grid_param_KNN = {\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['ball_tree', 'kd_tree'],\n",
    "    'n_neighbors' : [1,2,3,4,5,6,7]\n",
    "}\n",
    "\n",
    "grid_search_KNN = GridSearchCV(estimator = neighbors,  \n",
    "                              param_grid = grid_param_KNN,\n",
    "                              scoring = 'neg_mean_squared_error',\n",
    "                              cv = 5)\n",
    "\n",
    "grid_search_KNN.fit(testing_X, testing_Y)\n",
    "print('KNN recommended parameters:')\n",
    "print(grid_search_KNN.best_params_)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN recommended parameters:\n",
      "{'max_depth': None, 'max_features': 0.3, 'n_estimators': 5}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Gridsearch CV for the Random Forest algorithm\n",
    "rfc = ensemble.RandomForestClassifier(max_depth = None, max_features = 0.3, n_estimators = 5)\n",
    "\n",
    "grid_param_RFC = {\n",
    "    'max_features': [.1,.3,.5,.7,.9,'sqrt','log2'],\n",
    "    'max_depth': [None,1,2,3,4,5],\n",
    "    'n_estimators' : [2,5,8,9,10,11,12,15,18,20]\n",
    "}\n",
    "\n",
    "grid_search_RFC = GridSearchCV(estimator = rfc,  \n",
    "                              param_grid = grid_param_RFC,\n",
    "                              scoring = 'neg_mean_squared_error',\n",
    "                              cv = 5)\n",
    "\n",
    "grid_search_RFC.fit(testing_X, testing_Y)\n",
    "print('Random Forest recommended parameters:')\n",
    "print(grid_search_RFC.best_params_)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression recommended parameters:\n",
      "{'C': 1, 'penalty': 'l1'}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Gridsearch CV for the Logistic Regression algorithm\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=.9, solver='liblinear')\n",
    "\n",
    "grid_param_LR = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [1,.1,.3,.5,.7,.9]\n",
    "#   , 'solver' : ['liblinear','saga']\n",
    "# Repeated warnings about iter limits being exceeded resulted from including the previous line in the code\n",
    "}\n",
    "\n",
    "grid_search_LR = GridSearchCV(estimator = lr,  \n",
    "                              param_grid = grid_param_LR,\n",
    "                              scoring = 'neg_mean_squared_error',\n",
    "                              cv = 5)\n",
    "\n",
    "grid_search_LR.fit(testing_X, testing_Y)\n",
    "print('Logistic Regression recommended parameters:')\n",
    "print(grid_search_LR.best_params_)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch CV for the Gradient Boosting Classifier algorithm\n",
    "# Warning, this takes a LONG time to run...\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier(n_estimators=100,max_depth=2)\n",
    "\n",
    "grid_param_GBC = {\n",
    "    'n_estimators': [100,75,200],\n",
    "    'learning_rate': [.1,.08,.12], \n",
    "    'criterion' : ['friedman_mse','mse','mae'],\n",
    "    'max_depth': [1,2,3,4,5]\n",
    "}\n",
    "\n",
    "grid_search_GBC = GridSearchCV(estimator = clf,  \n",
    "                              param_grid = grid_param_GBC,\n",
    "                              scoring = 'neg_mean_squared_error',\n",
    "                              cv = 5)\n",
    "\n",
    "grid_search_GBC.fit(testing_X, testing_Y)\n",
    "print('Gradient Boosting Classifier recommended parameters:')\n",
    "print(grid_search_GBC.best_params_)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch CV for the SVM algorithm\n",
    "# Warning, this takes a LONG time to run...\n",
    "\n",
    "svm = SVC(kernel = 'linear')\n",
    "\n",
    "grid_param_SVM = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 'auto']\n",
    "}\n",
    "\n",
    "grid_search_SVM = GridSearchCV(estimator = clf,  \n",
    "                              param_grid = grid_param_SVM,\n",
    "                              scoring = 'neg_mean_squared_error',\n",
    "                              cv = 5)\n",
    "\n",
    "grid_search_SVM.fit(testing_X, testing_Y)\n",
    "print('Gradient Boosting Classifier recommended parameters:')\n",
    "print(grid_search_SVM.best_params_)\n",
    "print(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier recommended parameters:\n",
      "{'criterion': 'entropy', 'max_depth': 3, 'max_features': 0.7}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Gridsearch CV for the Decision Tree algorithm\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "\n",
    "grid_param_DT = {\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2', 2, .1,.3,.5,.7,.9], \n",
    "    'criterion' : ['entropy','gini'],\n",
    "    'max_depth': [1,2,3,4,5]\n",
    "}\n",
    "\n",
    "grid_search_DT = GridSearchCV(estimator = dtree,  \n",
    "                              param_grid = grid_param_DT,\n",
    "                              scoring = 'neg_mean_squared_error',\n",
    "                              cv = 5)\n",
    "\n",
    "grid_search_DT.fit(testing_X, testing_Y)\n",
    "print('Decision Tree Classifier recommended parameters:')\n",
    "print(grid_search_DT.best_params_)\n",
    "print(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN results:\n",
      " \n",
      "Model score:\n",
      "0.9984375274310493\n",
      " \n",
      "Confusion Matrix (UL: True Negative, UR: False Positive, BL: False Negative, BR: True Positive)\n",
      "[[56863     1]\n",
      " [   88     9]]\n",
      " \n",
      "Accuracy:\n",
      "0.9984375274310493\n",
      " \n",
      "Recall/Sensitivity (% of late arrivals predicted):\n",
      "0.09278350515463918\n",
      " \n",
      "Precision (% of on-time arrivals predicted accurately):\n",
      "0.9\n",
      " \n",
      "AUC score:0.546\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.03941016 0.2878083  0.64870084 0.99833216 0.99833202]\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "neighbors = KNeighborsClassifier(weights='uniform', n_neighbors=2, algorithm= 'ball_tree')\n",
    "neighbors.fit(training_X,training_Y)\n",
    "print('KNN results:')\n",
    "print(' ')\n",
    "accuracy_report(testing_X, testing_Y, neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.9995084355962852\n",
      " \n",
      "Confusion Matrix (UL: True Negative, UR: False Positive, BL: False Negative, BR: True Positive)\n",
      "[[56852    12]\n",
      " [   16    81]]\n",
      " \n",
      "Accuracy:\n",
      "0.9995084355962852\n",
      " \n",
      "Recall/Sensitivity (% of late arrivals predicted):\n",
      "0.8350515463917526\n",
      " \n",
      "Precision (% of on-time arrivals predicted accurately):\n",
      "0.8709677419354839\n",
      " \n",
      "AUC score:0.917\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.99526025 0.99929781 0.99912219 0.99903441 0.99938548]\n"
     ]
    }
   ],
   "source": [
    "# RFC\n",
    "rfc = ensemble.RandomForestClassifier(max_depth = None, max_features = 0.3, n_estimators = 5)\n",
    "rfc.fit(training_X,training_Y)\n",
    "print('RFC results:')\n",
    "print(' ')\n",
    "accuracy_report(testing_X, testing_Y, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression results:\n",
      " \n",
      "Model score:\n",
      "0.9991046505503766\n",
      " \n",
      "Confusion Matrix (UL: True Negative, UR: False Positive, BL: False Negative, BR: True Positive)\n",
      "[[56848    16]\n",
      " [   35    62]]\n",
      " \n",
      "Accuracy:\n",
      "0.9991046505503766\n",
      " \n",
      "Recall/Sensitivity (% of late arrivals predicted):\n",
      "0.6391752577319587\n",
      " \n",
      "Precision (% of on-time arrivals predicted accurately):\n",
      "0.7948717948717948\n",
      " \n",
      "AUC score:0.819\n",
      " \n",
      "Model cross-valuation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99859563 0.99929781 0.99894663 0.99868329 0.99885875]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(penalty='l1', C=.9)\n",
    "lr.fit(training_X,training_Y)\n",
    "print('Logistic Regression results:')\n",
    "print(' ')\n",
    "accuracy_report(testing_X, testing_Y, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC results:\n",
      " \n",
      "Model score:\n",
      "0.9989466477063254\n",
      " \n",
      "Confusion Matrix (UL: True Negative, UR: False Positive, BL: False Negative, BR: True Positive)\n",
      "[[56855     9]\n",
      " [   51    46]]\n",
      " \n",
      "Accuracy:\n",
      "0.9989466477063254\n",
      " \n",
      "Recall/Sensitivity (% of late arrivals predicted):\n",
      "0.4742268041237113\n",
      " \n",
      "Precision (% of on-time arrivals predicted accurately):\n",
      "0.8363636363636363\n",
      " \n",
      "AUC score:0.737\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.28824717 0.99956113 0.99806882 0.99894663 0.99929769]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier(n_estimators=300,max_depth=2)\n",
    "clf.fit(training_X,training_Y)\n",
    "print('GBC results:')\n",
    "print(' ')\n",
    "accuracy_report(testing_X, testing_Y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM results:\n",
      " \n",
      "Model score:\n",
      "0.998490195045733\n",
      " \n",
      "Confusion Matrix (UL: True Negative, UR: False Positive, BL: False Negative, BR: True Positive)\n",
      "[[56839    25]\n",
      " [   61    36]]\n",
      " \n",
      "Accuracy:\n",
      "0.998490195045733\n",
      " \n",
      "Recall/Sensitivity (% of late arrivals predicted):\n",
      "0.3711340206185567\n",
      " \n",
      "Precision (% of on-time arrivals predicted accurately):\n",
      "0.5901639344262295\n",
      " \n",
      "AUC score:0.685\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.9878873  0.99877118 0.99833216 0.99833216 0.99833202]\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(training_X,training_Y)\n",
    "print('SVM results:')\n",
    "print(' ')\n",
    "accuracy_report(testing_X, testing_Y, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree results:\n",
      " \n",
      "Model score:\n",
      "0.999280209265989\n",
      " \n",
      "Confusion Matrix (UL: True Negative, UR: False Positive, BL: False Negative, BR: True Positive)\n",
      "[[56838    26]\n",
      " [   15    82]]\n",
      " \n",
      "Accuracy:\n",
      "0.999280209265989\n",
      " \n",
      "Recall/Sensitivity (% of late arrivals predicted):\n",
      "0.845360824742268\n",
      " \n",
      "Precision (% of on-time arrivals predicted accurately):\n",
      "0.7592592592592593\n",
      " \n",
      "AUC score:0.922\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.99833231 0.99885895 0.99920997 0.99912219 0.9992099 ]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "dtree = tree.DecisionTreeClassifier(criterion='entropy', max_features=.7, max_depth=3)\n",
    "dtree.fit(training_X,training_Y)\n",
    "print('Decision Tree results:')\n",
    "print(' ')\n",
    "accuracy_report(testing_X, testing_Y, dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes results:\n",
      " \n",
      "Model score:\n",
      "0.9989993153210092\n",
      " \n",
      "Confusion Matrix (UL: True Negative, UR: False Positive, BL: False Negative, BR: True Positive)\n",
      "[[56839    25]\n",
      " [   32    65]]\n",
      " \n",
      "Accuracy:\n",
      "0.9989993153210092\n",
      " \n",
      "Recall/Sensitivity (% of late arrivals predicted):\n",
      "0.6701030927835051\n",
      " \n",
      "Precision (% of on-time arrivals predicted accurately):\n",
      "0.7222222222222222\n",
      " \n",
      "AUC score:0.835\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.99824454 0.99964891 0.99885885 0.99885885 0.99947327]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(training_X,training_Y)\n",
    "print('Naive Bayes results:')\n",
    "print(' ')\n",
    "accuracy_report(testing_X, testing_Y, bnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN\n",
    "Recall: 0.092\n",
    "\n",
    "AUC: .546\n",
    "\n",
    "#### Random Forest Classifier\n",
    "Recall: .794\n",
    "\n",
    "AUC: .897\n",
    "\n",
    "#### Logistic Regression\n",
    "Recall: .639\n",
    "\n",
    "AUC: .819\n",
    "\n",
    "#### Gradient Boosted Classifier\n",
    "Recall: .474\n",
    "\n",
    "AUC: .737\n",
    "\n",
    "#### Linear SVM\n",
    "Recall: .371\n",
    "\n",
    "AUC: .685\n",
    "\n",
    "#### Decision Tree\n",
    "Recall: .84\n",
    "\n",
    "AUC: .922\n",
    "\n",
    "#### Naive Bayes\n",
    "Recall: .67\n",
    "\n",
    "AUC: .835"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest and Decision Tree algorithms resulted in moderately high accuracy within the bounds of the dataset provided.  Naive Bayes and Logistic Regression resulted in mediocre but still above-average accuracy.  All other algorithms result in unacceptably high false negative results.  \n",
    "\n",
    "Random Forest and Decision Tree both benefitted from being ensemble models, which was likely what gave them the ability to figure out the signs that a transaction was fraudulent.  \n",
    "\n",
    "Logistic Regression benefitted from the fact that it has a built-in mathematical boost towards modeling binary solutions.  However, judging by the fact that Naive Bayes, the simplest model in this selection, performed better than all the others except for RFC and DT, there's likely a relatively simple means of calculating whether a transaction is fraudulent, but the more complicated models (except for DT & RF) got distracted by other variables, lowering their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
