{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is 20 (or 19, for BoW testing) novels by four authors.\n",
    "\n",
    "tf-idf and BoW were attempted as NLP methods. BoW and proved to be _far_ worse than tf-idf. SVD was performed on the tf-idf data, but proved to be harmful to performance rather than helpful.\n",
    "\n",
    "Current best-attempt is an RFC model attempting to predict the author of a text using tf-idf data collected from all of the texts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.7949438202247191\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.84      0.85      0.85      2525\n",
      "     Dickens       0.79      0.87      0.83      4375\n",
      "   Stevenson       0.79      0.46      0.58      1376\n",
      "       Twain       0.76      0.78      0.77      3116\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     11392\n",
      "   macro avg       0.80      0.74      0.76     11392\n",
      "weighted avg       0.79      0.79      0.79     11392\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.70307018 0.67954346 0.68261633 0.69315189 0.70851624]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/morgankauffman/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "import math\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"scipy\",\n",
    "    message=\"^internal gelsd\"\n",
    ")\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import neighbors\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from nltk.tokenize import BlanklineTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import urllib.request\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import os\n",
    "\n",
    "import pydotplus\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_punct(text):\n",
    "    text = text.replace('\"','')\n",
    "    text = text.replace('“','')\n",
    "    text = text.replace('”','')\n",
    "    text = text.replace('\\'','')\n",
    "    text = text.replace('.',' .')\n",
    "    text = text.replace(',',' ,')\n",
    "    text = text.replace('?',' ?')\n",
    "    text = text.replace('!',' !')\n",
    "    text = text.replace(':',' :')\n",
    "    text = text.replace(';',' ;')\n",
    "    text = text.replace('(','( ')\n",
    "    text = text.replace(')',' )')\n",
    "    text = text.replace('-', ' - ')\n",
    "    return text\n",
    "\n",
    "def get_texts(text_url):\n",
    "    values = {'q' : 'python programming tutorials'}\n",
    "    data = urllib.parse.urlencode(values)\n",
    "    data = data.encode('utf-8') # data should be bytes\n",
    "    req = urllib.request.Request(text_url, data)\n",
    "    resp = urllib.request.urlopen(req)\n",
    "    respData = resp.read()\n",
    "    text = respData.decode(\"utf-8\")\n",
    "    text = text.replace('_','')\n",
    "    text = text.replace('\\xa0', '')\n",
    "    text = text.replace(',—', ', ')\n",
    "    text = text.replace('--', ' - ')\n",
    "    text = clean_punct(text)\n",
    "    return text\n",
    "    \n",
    "def get_paragraphs(text_url):\n",
    "    values = {'q' : 'python programming tutorials'}\n",
    "    data = urllib.parse.urlencode(values)\n",
    "    data = data.encode('utf-8') # data should be bytes\n",
    "    req = urllib.request.Request(text_url, data)\n",
    "    resp = urllib.request.urlopen(req)\n",
    "    respData = resp.read()\n",
    "    text = respData.decode(\"utf-8\")\n",
    "    text = text.replace('_','')\n",
    "    text = text.replace('\\xa0', '')\n",
    "    text = text.replace(',—', ', ')\n",
    "    text = text.replace('--', ' - ')\n",
    "    text = clean_punct(text)\n",
    "    paragraphs = BlanklineTokenizer().tokenize(text)\n",
    "    cleaned_paras = []\n",
    "    for para in paragraphs:\n",
    "        cleaned_paras.append(para.replace(\"\\r\\n\", \" \"))\n",
    "    return cleaned_paras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorizer(text,maxdf,mindf):\n",
    "    vectorizer = TfidfVectorizer(max_df=maxdf, # drop words that occur in more than X% the paragraphs\n",
    "                                 min_df=mindf, # only use words that appear at least Y times\n",
    "                                 stop_words='english', \n",
    "                                 lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                                 use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                                 norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                                 smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                                )\n",
    "\n",
    "\n",
    "    #Applying the vectorizer\n",
    "    text_tfidf=vectorizer.fit_transform(text)\n",
    "    print(\"Number of features: %d\" % text_tfidf.get_shape()[1])\n",
    "\n",
    "    #Reshapes the vectorizer output into something people can read\n",
    "    text_tfidf_csr = text_tfidf.tocsr()\n",
    "    #number of paragraphs\n",
    "    n = text_tfidf_csr.shape[0]\n",
    "    #A list of dictionaries, one per paragraph\n",
    "    tfidf_bypara = [{} for _ in range(0,n)]\n",
    "    #List of features\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    #for each paragraph, lists the feature words and their tf-idf scores\n",
    "    for i, j in zip(*text_tfidf_csr.nonzero()):\n",
    "        tfidf_bypara[i][terms[j]] = text_tfidf_csr[i, j]\n",
    "\n",
    "    vocabulary_list = list(vectorizer.vocabulary_.keys())\n",
    "\n",
    "    #Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present \n",
    "    #once in that sentence.\n",
    "    return text_tfidf_csr, text_tfidf, tfidf_bypara, vocabulary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_reducer(text_tfidf, text, svdnum):\n",
    "    #Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130.\n",
    "    svd= TruncatedSVD(svdnum)\n",
    "    lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "    # Run SVD on the training data, then project the training data.\n",
    "    text_lsa = lsa.fit_transform(text_tfidf)\n",
    "\n",
    "    variance_explained=svd.explained_variance_ratio_\n",
    "    total_variance = variance_explained.sum()\n",
    "    print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "    return text_lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dfidf_dataframe(author, title, paragraph_list, book_text):\n",
    "    df_idf_dataframe = pd.DataFrame(columns = ['author','title','paragraph'])\n",
    "    counter = 0\n",
    "\n",
    "    for para in paragraph_list:\n",
    "        df_idf_dataframe.loc[counter,'paragraph'] = book_text[counter]\n",
    "\n",
    "        word_list = list(para.keys())\n",
    "\n",
    "        for word in word_list:\n",
    "            df_idf_dataframe.loc[counter,word] = para[word]\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    df_idf_dataframe['author'] = author\n",
    "    df_idf_dataframe['title'] = title\n",
    "\n",
    "    df_idf_dataframe = df_idf_dataframe.fillna(0)\n",
    "    return df_idf_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_text_make_df(url,author,title,max_df,min_df):\n",
    "    book_text = get_paragraphs(url)\n",
    "    tfidf_csr, text_tfidf, book_paras, vocabulary_list = tfidf_vectorizer(book_text, max_df, min_df)\n",
    "    book_df = write_dfidf_dataframe(author,title,book_paras,book_text)\n",
    "    os.system('say \"all done.\"'); print('\\a')  # this could take a while, let me know when it's done\n",
    "    return book_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df = .1\n",
    "min_df = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1416\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "prideandprejudice_Austen = grab_text_make_df('http://www.gutenberg.org/files/1342/1342-0.txt',\n",
    "                                             'Austen',\n",
    "                                             'Pride and Prejudice',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1398\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "ladysusan_Austen = grab_text_make_df('http://www.gutenberg.org/cache/epub/21839/pg21839.txt', \n",
    "                                            'Austen', \n",
    "                                            'Lady Susan',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1660\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "mansfieldpark_Austen = grab_text_make_df('http://www.gutenberg.org/files/141/141-0.txt', \n",
    "                                            'Austen', \n",
    "                                            'Mansfield Park',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1582\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "emma_Austen = grab_text_make_df('http://www.gutenberg.org/files/158/158-0.txt', \n",
    "                                            'Austen', \n",
    "                                            'Emma',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1361\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "sensesensibility_Austen = grab_text_make_df('http://www.gutenberg.org/cache/epub/161/pg161.txt', \n",
    "                                            'Austen', \n",
    "                                            'Sense and Sensibility',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1135\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "huckleberryfinn_Twain = grab_text_make_df('http://www.gutenberg.org/files/76/76-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'The Adventures of Huckleberry Finn',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1005\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "princeandpauper_Twain = grab_text_make_df('http://www.gutenberg.org/files/1837/1837-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'The Prince and the Pauper',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1995\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "trampabroad_Twain = grab_text_make_df('http://www.gutenberg.org/files/119/119-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'A Tramp Abroad',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1398\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "yankeeinkingarthurscourt_Twain = grab_text_make_df('http://www.gutenberg.org/files/86/86-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'A Connecticut Yankee in King Arthurs Court',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 933\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "tomsawyer_Twain = grab_text_make_df('http://www.gutenberg.org/files/74/74-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'The Adventures of Tom Sawyer',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1819\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "lifeonthemississippi_Twain = grab_text_make_df('http://www.gutenberg.org/files/245/245-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'Life on the Mississippi',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1837\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "greatexpectations_Dickens = grab_text_make_df('http://www.gutenberg.org/files/1400/1400-0.txt',\n",
    "                                             'Dickens',\n",
    "                                             'Great Expectations',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1562\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "taleoftwocities_Dickens = grab_text_make_df('http://www.gutenberg.org/files/98/98-0.txt', \n",
    "                                            'Dickens', \n",
    "                                            'A Tale of Two Cities',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 337\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "christmascarol_Dickens = grab_text_make_df('http://www.gutenberg.org/files/46/46-0.txt', \n",
    "                                            'Dickens', \n",
    "                                            'A Christmas Carol',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1106\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "hardtimes_Dickens = grab_text_make_df('http://www.gutenberg.org/files/786/786-0.txt', \n",
    "                                            'Dickens', \n",
    "                                            'Hard Times',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1946\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "olivertwist_Dickens = grab_text_make_df('http://www.gutenberg.org/cache/epub/730/pg730.txt', \n",
    "                                            'Dickens', \n",
    "                                            'Oliver Twist',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 287\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "drjekyllmrhyde_Stevenson = grab_text_make_df('http://www.gutenberg.org/files/43/43-0.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'Treasure Island',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 868\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "treasureisland_Stevenson = grab_text_make_df('http://www.gutenberg.org/files/120/120-0.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'Treasure Island',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1087\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "blackarrow_Stevenson = grab_text_make_df('http://www.gutenberg.org/cache/epub/32954/pg32954.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'The Black Arrow',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 931\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "kidnapped_Stevenson = grab_text_make_df('http://www.gutenberg.org/files/421/421-0.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'Kidnapped',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 994\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "merrymen_Stevenson = grab_text_make_df('http://www.gutenberg.org/cache/epub/344/pg344.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'The Merry Men',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21158, 3201)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_book_list = [prideandprejudice_Austen, \n",
    "                   huckleberryfinn_Twain,\n",
    "                   greatexpectations_Dickens,\n",
    "                   drjekyllmrhyde_Stevenson]\n",
    "\n",
    "small_combined_df = pd.DataFrame(columns = ['author','title','paragraph'])\n",
    "small_combined_df = combined_df.append(small_book_list, sort=False)\n",
    "small_combined_df = small_combined_df.fillna(0)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this could take a while, let me know when it's done\n",
    "small_combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56960, 5916)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_book_list = [prideandprejudice_Austen,\n",
    "             ladysusan_Austen,\n",
    "             mansfieldpark_Austen,\n",
    "             emma_Austen,\n",
    "             sensesensibility_Austen,\n",
    "             huckleberryfinn_Twain,\n",
    "             princeandpauper_Twain,\n",
    "             trampabroad_Twain,\n",
    "             yankeeinkingarthurscourt_Twain,\n",
    "             tomsawyer_Twain,\n",
    "             lifeonthemississippi_Twain,\n",
    "             greatexpectations_Dickens,\n",
    "             taleoftwocities_Dickens,\n",
    "             christmascarol_Dickens,\n",
    "             hardtimes_Dickens,\n",
    "             olivertwist_Dickens,\n",
    "             drjekyllmrhyde_Stevenson,\n",
    "             treasureisland_Stevenson,\n",
    "             blackarrow_Stevenson,\n",
    "             kidnapped_Stevenson,\n",
    "             merrymen_Stevenson]\n",
    "\n",
    "big_combined_df = pd.DataFrame(columns = ['author','title','paragraph'])\n",
    "big_combined_df = combined_df.append(big_book_list, sort=False)\n",
    "big_combined_df = big_combined_df.fillna(0)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this could take a while, let me know when it's done\n",
    "big_combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_report(testing_X, testing_Y, model, cross_valuation_yesno):\n",
    "    predictions = model.predict(testing_X)\n",
    "    print('Model score:')\n",
    "    print(model.score(testing_X, testing_Y))\n",
    "    print(\" \")\n",
    "    print(\"Classification Report:\")\n",
    "    y_prediction = model.predict(testing_X)\n",
    "    print(classification_report(testing_Y, y_prediction))\n",
    "    \n",
    "# Sometimes we don't want to spend the processor time calculating the cross-valuation, so we need a way to toggle it.\n",
    "    if cross_valuation_yesno == 1:\n",
    "        print(\" \")\n",
    "        print('Model cross-valuation:')\n",
    "        print(sklearn.model_selection.cross_val_score(model, testing_X, testing_Y, cv = 5))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = small_combined_df['author']\n",
    "X = small_combined_df.drop(['author','title','paragraph'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.9187145557655955\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.96      0.90      0.93       869\n",
      "     Dickens       0.90      0.97      0.93      2294\n",
      "   Stevenson       0.71      0.11      0.20        87\n",
      "       Twain       0.95      0.88      0.91       982\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      4232\n",
      "   macro avg       0.88      0.72      0.74      4232\n",
      "weighted avg       0.92      0.92      0.91      4232\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.79009434 0.78773585 0.80614657 0.8250591  0.78909953]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('RFC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, rfc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC results:\n",
      " \n",
      "Model score:\n",
      "0.7651228733459358\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       1.00      0.49      0.66       869\n",
      "     Dickens       0.70      0.99      0.82      2294\n",
      "   Stevenson       0.85      0.33      0.48        87\n",
      "       Twain       0.98      0.52      0.68       982\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      4232\n",
      "   macro avg       0.88      0.58      0.66      4232\n",
      "weighted avg       0.83      0.77      0.75      4232\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.72169811 0.74646226 0.74231678 0.76122931 0.73815166]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "print('GBC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, gbc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN results:\n",
      " \n",
      "Model score:\n",
      "0.581758034026465\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.54      0.24      0.33       869\n",
      "     Dickens       0.65      0.75      0.70      2294\n",
      "   Stevenson       0.25      0.02      0.04        87\n",
      "       Twain       0.44      0.55      0.49       982\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      4232\n",
      "   macro avg       0.47      0.39      0.39      4232\n",
      "weighted avg       0.57      0.58      0.56      4232\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.4504717  0.45636792 0.46808511 0.4964539  0.47156398]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "neighbors = KNeighborsClassifier()\n",
    "neighbors.fit(X_train, y_train)\n",
    "print('KNN results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, neighbors, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = big_combined_df['author']\n",
    "X = big_combined_df.drop(['author','title','paragraph'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.7949438202247191\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.84      0.85      0.85      2525\n",
      "     Dickens       0.79      0.87      0.83      4375\n",
      "   Stevenson       0.79      0.46      0.58      1376\n",
      "       Twain       0.76      0.78      0.77      3116\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     11392\n",
      "   macro avg       0.80      0.74      0.76     11392\n",
      "weighted avg       0.79      0.79      0.79     11392\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.70307018 0.67954346 0.68261633 0.69315189 0.70851624]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('RFC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, rfc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words, title):\n",
    "    column_names = ['author', 'title', 'text_sentence']\n",
    "    column_names = column_names.append(common_words)\n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "    df['text_sentence'] = sentences[1]\n",
    "    df['author'] = sentences[0]\n",
    "    df['title'] = title\n",
    "    for word in common_words:\n",
    "        df.loc[:, word] = 0\n",
    "\n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence'][::100]):\n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_bow_df(url,author,title):\n",
    "    bow_df_txt = get_texts(url)  # extract the text from the url\n",
    "    bow_df_txt = text_cleaner(bow_df_txt)  # do a basic clean of the text\n",
    "    bow_df_doc = nlp(bow_df_txt)  # convert the massive str into a nlp document\n",
    "    bow_df_sents = [[author, sent] for sent in bow_df_doc.sents]  # convert the document into sentences\n",
    "    sentences = pd.DataFrame(bow_df_sents)  # create a dataframe of those sentences\n",
    "    bow_df_words = bag_of_words(bow_df_doc)  # Create a bag of words with the top 2000 most common words\n",
    "#    common_words = set(bow_df_words)\n",
    "    \n",
    "    # Create a new data frame with the combined features of words & sentences; this can take a while to run.\n",
    "    bow_df = bow_features(sentences, common_words, title)\n",
    "    bow_df['author'] = author\n",
    "    return bow_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n"
     ]
    }
   ],
   "source": [
    "prideandprejudice_Austen_bow = get_bow_df('http://www.gutenberg.org/files/1342/1342-0.txt',\n",
    "                                             'Austen',\n",
    "                                             'Pride and Prejudice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n"
     ]
    }
   ],
   "source": [
    "ladysusan_Austen_bow = get_bow_df('http://www.gutenberg.org/cache/epub/21839/pg21839.txt', \n",
    "                                            'Austen', \n",
    "                                            'Lady Susan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n"
     ]
    }
   ],
   "source": [
    "mansfieldpark_Austen_bow = get_bow_df('http://www.gutenberg.org/files/141/141-0.txt', \n",
    "                                            'Austen', \n",
    "                                            'Mansfield Park')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n"
     ]
    }
   ],
   "source": [
    "emma_Austen_bow = get_bow_df('http://www.gutenberg.org/files/158/158-0.txt', \n",
    "                                            'Austen', \n",
    "                                            'Emma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n"
     ]
    }
   ],
   "source": [
    "sensesensibility_Austen_bow = get_bow_df('http://www.gutenberg.org/cache/epub/161/pg161.txt', \n",
    "                                            'Austen', \n",
    "                                            'Sense and Sensibility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n"
     ]
    }
   ],
   "source": [
    "huckleberryfinn_Twain_bow = get_bow_df('http://www.gutenberg.org/files/76/76-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'The Adventures of Huckleberry Finn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n"
     ]
    }
   ],
   "source": [
    "princeandpauper_Twain_bow = get_bow_df('http://www.gutenberg.org/files/1837/1837-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'The Prince and the Pauper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n"
     ]
    }
   ],
   "source": [
    "trampabroad_Twain_bow = get_bow_df('http://www.gutenberg.org/files/119/119-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'A Tramp Abroad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n"
     ]
    }
   ],
   "source": [
    "yankeeinkingarthurscourt_Twain_bow = get_bow_df('http://www.gutenberg.org/files/86/86-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'A Connecticut Yankee in King Arthurs Court')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n"
     ]
    }
   ],
   "source": [
    "tomsawyer_Twain_bow = get_bow_df('http://www.gutenberg.org/files/74/74-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'The Adventures of Tom Sawyer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n"
     ]
    }
   ],
   "source": [
    "lifeonthemississippi_Twain_bow = get_bow_df('http://www.gutenberg.org/files/245/245-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'Life on the Mississippi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great Expectations exceeded the text limit for python, and was removed from the working lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n"
     ]
    }
   ],
   "source": [
    "taleoftwocities_Dickens_bow = get_bow_df('http://www.gutenberg.org/files/98/98-0.txt', \n",
    "                                            'Dickens', \n",
    "                                            'A Tale of Two Cities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n"
     ]
    }
   ],
   "source": [
    "christmascarol_Dickens_bow = get_bow_df('http://www.gutenberg.org/files/46/46-0.txt', \n",
    "                                            'Dickens', \n",
    "                                            'A Christmas Carol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n"
     ]
    }
   ],
   "source": [
    "hardtimes_Dickens_bow = get_bow_df('http://www.gutenberg.org/files/786/786-0.txt', \n",
    "                                            'Dickens', \n",
    "                                            'Hard Times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n"
     ]
    }
   ],
   "source": [
    "olivertwist_Dickens_bow = get_bow_df('http://www.gutenberg.org/cache/epub/730/pg730.txt', \n",
    "                                            'Dickens', \n",
    "                                            'Oliver Twist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n"
     ]
    }
   ],
   "source": [
    "drjekyllmrhyde_Stevenson_bow = get_bow_df('http://www.gutenberg.org/files/43/43-0.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'Treasure Island')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n"
     ]
    }
   ],
   "source": [
    "treasureisland_Stevenson_bow = get_bow_df('http://www.gutenberg.org/files/120/120-0.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'Treasure Island')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n"
     ]
    }
   ],
   "source": [
    "kidnapped_Stevenson_bow = get_bow_df('http://www.gutenberg.org/files/421/421-0.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'Kidnapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n"
     ]
    }
   ],
   "source": [
    "merrymen_Stevenson_bow = get_bow_df('http://www.gutenberg.org/cache/epub/344/pg344.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'The Merry Men')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n"
     ]
    }
   ],
   "source": [
    "blackarrow_Stevenson_bow = get_bow_df('http://www.gutenberg.org/cache/epub/32954/pg32954.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'The Black Arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "os.system('say \"all done.\"'); print('\\a')  # this could take a while, let me know when it's done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the BoW compiled dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18158, 2002)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_bow_list = [prideandprejudice_Austen_bow, \n",
    "                   huckleberryfinn_Twain_bow,\n",
    "                   christmascarol_Dickens_bow,\n",
    "                   drjekyllmrhyde_Stevenson_bow]\n",
    "\n",
    "combined_df = pd.DataFrame(columns = ['text_sentence','author','title'])\n",
    "small_bow_df = combined_df.append(small_bow_list, sort=False)\n",
    "small_bow_df = small_bow_df.fillna(0)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this could take a while, let me know when it's done\n",
    "small_bow_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56960, 5916)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_bow_list = [prideandprejudice_Austen_bow,\n",
    "             ladysusan_Austen_bow,\n",
    "             mansfieldpark_Austen_bow,\n",
    "             emma_Austen_bow,\n",
    "             sensesensibility_Austen_bow,\n",
    "             huckleberryfinn_Twain_bow,\n",
    "             princeandpauper_Twain_bow,\n",
    "             trampabroad_Twain_bow,\n",
    "             yankeeinkingarthurscourt_Twain_bow,\n",
    "             tomsawyer_Twain_bow,\n",
    "             lifeonthemississippi_Twain_bow,\n",
    "             taleoftwocities_Dickens_bow,\n",
    "             christmascarol_Dickens_bow,\n",
    "             hardtimes_Dickens_bow,\n",
    "             olivertwist_Dickens_bow,\n",
    "             drjekyllmrhyde_Stevenson_bow,\n",
    "             treasureisland_Stevenson_bow,\n",
    "             blackarrow_Stevenson_bow,\n",
    "             kidnapped_Stevenson_bow,\n",
    "             merrymen_Stevenson_bow]\n",
    "\n",
    "big_bow_df = pd.DataFrame(columns = ['text_sentence','author','title'])\n",
    "big_bow_df = big_bow_df.append(big_bow_list, sort=False)\n",
    "big_bow_df = big_bow_df.fillna(0)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this could take a while, let me know when it's done\n",
    "big_combined_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW targeting author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = small_bow_df['author']\n",
    "X = small_bow_df.drop(['author','title','text_sentence'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.4107929515418502\n",
      " \n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.41      1.00      0.58      1483\n",
      "     Dickens       0.67      0.00      0.01       426\n",
      "   Stevenson       0.00      0.00      0.00       319\n",
      "       Twain       0.71      0.01      0.01      1404\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      3632\n",
      "   macro avg       0.45      0.25      0.15      3632\n",
      "weighted avg       0.52      0.41      0.24      3632\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.40934066 0.40715268 0.41127923 0.40909091 0.41022099]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('RFC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, rfc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC results:\n",
      " \n",
      "Model score:\n",
      "0.4107929515418502\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.41      1.00      0.58      1483\n",
      "     Dickens       0.67      0.00      0.01       426\n",
      "   Stevenson       0.00      0.00      0.00       319\n",
      "       Twain       0.82      0.01      0.01      1404\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      3632\n",
      "   macro avg       0.47      0.25      0.15      3632\n",
      "weighted avg       0.56      0.41      0.24      3632\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.41071429 0.40715268 0.41127923 0.40909091 0.40883978]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "print('GBC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, gbc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN results:\n",
      " \n",
      "Model score:\n",
      "0.4088656387665198\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.41      1.00      0.58      1483\n",
      "     Dickens       0.00      0.00      0.00       426\n",
      "   Stevenson       0.00      0.00      0.00       319\n",
      "       Twain       0.40      0.00      0.00      1404\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      3632\n",
      "   macro avg       0.20      0.25      0.15      3632\n",
      "weighted avg       0.32      0.41      0.24      3632\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.38324176 0.40577717 0.40990371 0.4077135  0.40883978]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "neighbors = KNeighborsClassifier()\n",
    "neighbors.fit(X_train, y_train)\n",
    "print('KNN results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, neighbors, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = big_bow_df['author']\n",
    "X = big_bow_df.drop(['author','title','text_sentence'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.3018530052943008\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.48      0.01      0.01      7944\n",
      "     Dickens       0.31      0.00      0.01      6054\n",
      "   Stevenson       0.47      0.00      0.00      3961\n",
      "       Twain       0.30      0.99      0.46      7729\n",
      "\n",
      "   micro avg       0.30      0.30      0.30     25688\n",
      "   macro avg       0.39      0.25      0.12     25688\n",
      "weighted avg       0.38      0.30      0.14     25688\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.30920413 0.3106267  0.31004282 0.30945893 0.3090555 ]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('RFC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, rfc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW targeting book title\n",
    "(it does much worse in the big list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = small_bow_df['title']\n",
    "X = small_bow_df.drop(['author','title','text_sentence'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.41051762114537443\n",
      " \n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                 A Christmas Carol       0.50      0.00      0.00       426\n",
      "               Pride and Prejudice       0.41      1.00      0.58      1483\n",
      "The Adventures of Huckleberry Finn       0.67      0.01      0.01      1404\n",
      "                   Treasure Island       0.00      0.00      0.00       319\n",
      "\n",
      "                         micro avg       0.41      0.41      0.41      3632\n",
      "                         macro avg       0.39      0.25      0.15      3632\n",
      "                      weighted avg       0.48      0.41      0.24      3632\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.40934066 0.40577717 0.41127923 0.4077135  0.41022099]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('RFC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, rfc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC results:\n",
      " \n",
      "Model score:\n",
      "0.4107929515418502\n",
      " \n",
      "Classification Report:\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                 A Christmas Carol       0.67      0.00      0.01       426\n",
      "               Pride and Prejudice       0.41      1.00      0.58      1483\n",
      "The Adventures of Huckleberry Finn       0.82      0.01      0.01      1404\n",
      "                   Treasure Island       0.00      0.00      0.00       319\n",
      "\n",
      "                         micro avg       0.41      0.41      0.41      3632\n",
      "                         macro avg       0.47      0.25      0.15      3632\n",
      "                      weighted avg       0.56      0.41      0.24      3632\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.41071429 0.40715268 0.41127923 0.40909091 0.40883978]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "print('GBC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, gbc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = big_bow_df['title']\n",
    "X = big_bow_df.drop(['author','title','text_sentence'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.08727810650887574\n",
      " \n",
      "Classification Report:\n",
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "                         A Christmas Carol       0.14      0.00      0.00       443\n",
      "A Connecticut Yankee in King Arthurs Court       0.08      0.00      0.00      1269\n",
      "                      A Tale of Two Cities       0.10      0.00      0.00      1760\n",
      "                            A Tramp Abroad       0.00      0.00      0.00      1676\n",
      "                                      Emma       0.09      0.99      0.16      2232\n",
      "                                Hard Times       0.00      0.00      0.00      1734\n",
      "                                 Kidnapped       0.22      0.00      0.00       858\n",
      "                                Lady Susan       0.00      0.00      0.00      1280\n",
      "                   Life on the Mississippi       0.14      0.00      0.00      1569\n",
      "                            Mansfield Park       0.05      0.00      0.00      1607\n",
      "                              Oliver Twist       0.11      0.00      0.00      2117\n",
      "                       Pride and Prejudice       0.12      0.00      0.00      1525\n",
      "                     Sense and Sensibility       0.00      0.00      0.00      1300\n",
      "        The Adventures of Huckleberry Finn       0.17      0.00      0.00      1372\n",
      "              The Adventures of Tom Sawyer       0.43      0.01      0.01      1055\n",
      "                           The Black Arrow       0.38      0.00      0.01      1074\n",
      "                             The Merry Men       0.00      0.00      0.00       842\n",
      "                 The Prince and the Pauper       0.50      0.00      0.01       788\n",
      "                           Treasure Island       0.00      0.00      0.00      1187\n",
      "\n",
      "                                 micro avg       0.09      0.09      0.09     25688\n",
      "                                 macro avg       0.13      0.05      0.01     25688\n",
      "                              weighted avg       0.11      0.09      0.02     25688\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.08728616 0.08749757 0.0868211  0.08687183 0.08732943]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=200, random_state=23)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('RFC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, rfc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ick.  That did even worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving tf-idf algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's try tweaking the max_df and min_df variables, as well as which books we include in our test sample.  (One of the issues we ran into with the first run was that the Jekyll & Hyde book was so much shorter than the rest, so there was a sampling imbalance that affected performance.)\n",
    "\n",
    "* max_df = .1, min_df = 7 --> RFC 91%, cross-val ~80%\n",
    "* max_df = .25, min_df = 10 --> RFC 84%, cross-val ~78%\n",
    "* max_df = .25, min_df = 7 --> RFC 83%, cross-val ~77%\n",
    "* max_df = .4, min_df = 8 --> RFC 84.8%, cross-val ~79%\n",
    "* max_df = .4, min_df = 15 --> RFC 85.5%, cross-val ~79%\n",
    "* max_df = .6, min_df = 15 --> RFC 85.3%, cross-val ~79%\n",
    "* max_df = .6, min_df = 10 --> RFC 85.4%, cross-val ~80.5%\n",
    "* max_df = .4, min_df = 10 --> RFC 85.4%, cross-val ~80.5%\n",
    "* max_df = .5, min_df = 10 --> RFC 85.4%, cross-val ~80.5%\n",
    "* max_df = .7, min_df = 10 --> RFC 85.4%, cross-val ~80.5%\n",
    "* max_df = .3, min_df = 10 --> RFC 84%, cross-val ~78.6%\n",
    "* max_df = .5, min_df = 12 --> RFC 85.6%, cross-val ~79.7%\n",
    "\n",
    "Looks like .5/10 is a reasonable balance between test result and cross-val result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df = .5\n",
    "min_df = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sense and Sensibility:\n",
      "Number of features: 979\n",
      "\u0007\n",
      "The Prince and the Pauper:\n",
      "Number of features: 623\n",
      "\u0007\n",
      "Hard Times:\n",
      "Number of features: 731\n",
      "\u0007\n",
      "Black Arrow:\n",
      "Number of features: 720\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "print('Sense and Sensibility:')\n",
    "sensesensibility_Austen = grab_text_make_df('http://www.gutenberg.org/cache/epub/161/pg161.txt', \n",
    "                                            'Austen', \n",
    "                                            'Sense and Sensibility',\n",
    "                                             max_df, min_df)\n",
    "print('The Prince and the Pauper:')\n",
    "princeandpauper_Twain = grab_text_make_df('http://www.gutenberg.org/files/1837/1837-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'The Prince and the Pauper',\n",
    "                                             max_df, min_df)\n",
    "print('Hard Times:')\n",
    "hardtimes_Dickens = grab_text_make_df('http://www.gutenberg.org/files/786/786-0.txt', \n",
    "                                            'Dickens', \n",
    "                                            'Hard Times',\n",
    "                                             max_df, min_df)\n",
    "print('Black Arrow:')\n",
    "blackarrow_Stevenson = grab_text_make_df('http://www.gutenberg.org/cache/epub/32954/pg32954.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'The Black Arrow',\n",
    "                                             max_df, min_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8143, 1766)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_book_list = [blackarrow_Stevenson, hardtimes_Dickens, princeandpauper_Twain, sensesensibility_Austen]\n",
    "\n",
    "small_combined_df = pd.DataFrame(columns = ['author','title','paragraph'])\n",
    "small_combined_df = small_combined_df.append(small_book_list, sort=False)\n",
    "small_combined_df = small_combined_df.fillna(0)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this could take a while, let me know when it's done\n",
    "small_combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = small_combined_df['author']\n",
    "X = small_combined_df.drop(['author','title','paragraph'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.85451197053407\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.91      0.84      0.87       382\n",
      "     Dickens       0.87      0.87      0.87       455\n",
      "   Stevenson       0.88      0.87      0.87       430\n",
      "       Twain       0.76      0.85      0.80       362\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1629\n",
      "   macro avg       0.86      0.85      0.85      1629\n",
      "weighted avg       0.86      0.85      0.86      1629\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.81957187 0.79816514 0.81846154 0.79384615 0.79692308]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=200, random_state=23)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('RFC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, rfc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pride and Prejudice:\n",
      "Number of features: 1011\n",
      "\u0007\n",
      "Lady Susan:\n",
      "Number of features: 1000\n",
      "\u0007\n",
      "Mansfield Park:\n",
      "Number of features: 1240\n",
      "\u0007\n",
      "Emma:\n",
      "Number of features: 1179\n",
      "\u0007\n",
      "The Adventures of Huckleberry Finn:\n",
      "Number of features: 807\n",
      "\u0007\n",
      "A Tramp Abroad:\n",
      "Number of features: 1358\n",
      "\u0007\n",
      "A Connecticut Yankee in King Arthurs Court:\n",
      "Number of features: 917\n",
      "\u0007\n",
      "The Adventures of Tom Sawyer:\n",
      "Number of features: 572\n",
      "\u0007\n",
      "Life on the Mississippi:\n",
      "Number of features: 1193\n",
      "\u0007\n",
      "Great Expectations:\n",
      "Number of features: 1314\n",
      "\u0007\n",
      "A Tale of Two Cities:\n",
      "Number of features: 1061\n",
      "\u0007\n",
      "A Christmas Carol:\n",
      "Number of features: 219\n",
      "\u0007\n",
      "Oliver Twist:\n",
      "Number of features: 1363\n",
      "\u0007\n",
      "Dr. Jekyll and Mr. Hyde:\n",
      "Number of features: 176\n",
      "\u0007\n",
      "Treasure Island:\n",
      "Number of features: 602\n",
      "\u0007\n",
      "Kidnapped:\n",
      "Number of features: 616\n",
      "\u0007\n",
      "Merry Men:\n",
      "Number of features: 621\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "print('Pride and Prejudice:')\n",
    "prideandprejudice_Austen = grab_text_make_df('http://www.gutenberg.org/files/1342/1342-0.txt',\n",
    "                                             'Austen',\n",
    "                                             'Pride and Prejudice',\n",
    "                                             max_df, min_df)\n",
    "print('Lady Susan:')\n",
    "ladysusan_Austen = grab_text_make_df('http://www.gutenberg.org/cache/epub/21839/pg21839.txt', \n",
    "                                            'Austen', \n",
    "                                            'Lady Susan',\n",
    "                                             max_df, min_df)\n",
    "print('Mansfield Park:')\n",
    "mansfieldpark_Austen = grab_text_make_df('http://www.gutenberg.org/files/141/141-0.txt', \n",
    "                                            'Austen', \n",
    "                                            'Mansfield Park',\n",
    "                                             max_df, min_df)\n",
    "print('Emma:')\n",
    "emma_Austen = grab_text_make_df('http://www.gutenberg.org/files/158/158-0.txt', \n",
    "                                            'Austen', \n",
    "                                            'Emma',\n",
    "                                             max_df, min_df)\n",
    "print('The Adventures of Huckleberry Finn:')\n",
    "huckleberryfinn_Twain = grab_text_make_df('http://www.gutenberg.org/files/76/76-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'The Adventures of Huckleberry Finn',\n",
    "                                             max_df, min_df)\n",
    "print('A Tramp Abroad:')\n",
    "trampabroad_Twain = grab_text_make_df('http://www.gutenberg.org/files/119/119-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'A Tramp Abroad',\n",
    "                                             max_df, min_df)\n",
    "print('A Connecticut Yankee in King Arthurs Court:')\n",
    "yankeeinkingarthurscourt_Twain = grab_text_make_df('http://www.gutenberg.org/files/86/86-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'A Connecticut Yankee in King Arthurs Court',\n",
    "                                             max_df, min_df)\n",
    "print('The Adventures of Tom Sawyer:')\n",
    "tomsawyer_Twain = grab_text_make_df('http://www.gutenberg.org/files/74/74-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'The Adventures of Tom Sawyer',\n",
    "                                             max_df, min_df)\n",
    "print('Life on the Mississippi:')\n",
    "lifeonthemississippi_Twain = grab_text_make_df('http://www.gutenberg.org/files/245/245-0.txt', \n",
    "                                            'Twain', \n",
    "                                            'Life on the Mississippi',\n",
    "                                             max_df, min_df)\n",
    "print('Great Expectations:')\n",
    "greatexpectations_Dickens = grab_text_make_df('http://www.gutenberg.org/files/1400/1400-0.txt',\n",
    "                                             'Dickens',\n",
    "                                             'Great Expectations',\n",
    "                                             max_df, min_df)\n",
    "print('A Tale of Two Cities:')\n",
    "taleoftwocities_Dickens = grab_text_make_df('http://www.gutenberg.org/files/98/98-0.txt', \n",
    "                                            'Dickens', \n",
    "                                            'A Tale of Two Cities',\n",
    "                                             max_df, min_df)\n",
    "print('A Christmas Carol:')\n",
    "christmascarol_Dickens = grab_text_make_df('http://www.gutenberg.org/files/46/46-0.txt', \n",
    "                                            'Dickens', \n",
    "                                            'A Christmas Carol',\n",
    "                                             max_df, min_df)\n",
    "print('Oliver Twist:')\n",
    "olivertwist_Dickens = grab_text_make_df('http://www.gutenberg.org/cache/epub/730/pg730.txt', \n",
    "                                            'Dickens', \n",
    "                                            'Oliver Twist',\n",
    "                                             max_df, min_df)\n",
    "print('Dr. Jekyll and Mr. Hyde:')\n",
    "drjekyllmrhyde_Stevenson = grab_text_make_df('http://www.gutenberg.org/files/43/43-0.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'Treasure Island',\n",
    "                                             max_df, min_df)\n",
    "print('Treasure Island:')\n",
    "treasureisland_Stevenson = grab_text_make_df('http://www.gutenberg.org/files/120/120-0.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'Treasure Island',\n",
    "                                             max_df, min_df)\n",
    "print('Kidnapped:')\n",
    "kidnapped_Stevenson = grab_text_make_df('http://www.gutenberg.org/files/421/421-0.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'Kidnapped',\n",
    "                                             max_df, min_df)\n",
    "print('Merry Men:')\n",
    "merrymen_Stevenson = grab_text_make_df('http://www.gutenberg.org/cache/epub/344/pg344.txt', \n",
    "                                            'Stevenson', \n",
    "                                            'The Merry Men',\n",
    "                                             max_df, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(44898, 4204)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_book_list = [prideandprejudice_Austen,\n",
    "             ladysusan_Austen,\n",
    "             mansfieldpark_Austen,\n",
    "             emma_Austen,\n",
    "             sensesensibility_Austen,\n",
    "             huckleberryfinn_Twain,\n",
    "             princeandpauper_Twain,\n",
    "             trampabroad_Twain,\n",
    "             yankeeinkingarthurscourt_Twain,\n",
    "             tomsawyer_Twain,\n",
    "             lifeonthemississippi_Twain,\n",
    "             greatexpectations_Dickens,\n",
    "             taleoftwocities_Dickens,\n",
    "             christmascarol_Dickens,\n",
    "             hardtimes_Dickens,\n",
    "             olivertwist_Dickens,\n",
    "             drjekyllmrhyde_Stevenson,\n",
    "             treasureisland_Stevenson,\n",
    "             blackarrow_Stevenson,\n",
    "             kidnapped_Stevenson,\n",
    "             merrymen_Stevenson]\n",
    "\n",
    "big_combined_df = pd.DataFrame(columns = ['author','title','paragraph'])\n",
    "big_combined_df = combined_df.append(big_book_list, sort=False)\n",
    "big_combined_df = big_combined_df.fillna(0)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this could take a while, let me know when it's done\n",
    "big_combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = big_combined_df['author']\n",
    "X = big_combined_df.drop(['author','title','paragraph'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.7894209354120267\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.92      0.83      0.87      2100\n",
      "     Dickens       0.76      0.81      0.79      2869\n",
      "   Stevenson       0.85      0.62      0.72      1399\n",
      "       Twain       0.72      0.82      0.77      2612\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      8980\n",
      "   macro avg       0.81      0.77      0.78      8980\n",
      "weighted avg       0.80      0.79      0.79      8980\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.70061213 0.72732332 0.73830735 0.74109131 0.72408027]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=200, random_state=23)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('RFC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, rfc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "The first version got a model score of 0.7949, with cross-val scores of 0.7031, 0.6795, 0.6826, 0.6932, and 0.7085.\n",
    "\n",
    "This got slightly _lower_ model score, but a better cross-val score, which fits with what we knew about the smaller test sample at this min/max_df setting.\n",
    "\n",
    "Now to tinker with condensing the feature-set.\n",
    "\n",
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8143, 1767)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_book_list = [blackarrow_Stevenson, hardtimes_Dickens, princeandpauper_Twain, sensesensibility_Austen]\n",
    "\n",
    "small_combined_df = pd.DataFrame(columns = ['author','title','paragraph'])\n",
    "small_combined_df = combined_df.append(small_book_list, sort=False)\n",
    "small_combined_df = small_combined_df.fillna(0)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this could take a while, let me know when it's done\n",
    "small_combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = small_combined_df['author']\n",
    "X = small_combined_df.drop(['author','title','paragraph'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_converter(svd_num, X):\n",
    "    #Our SVD data reducer.  We are going to reduce the feature space to 300 features to start with.\n",
    "    svd= TruncatedSVD(svd_num)\n",
    "    lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "    # Run SVD on the training data, then project the training data.\n",
    "    X_lsa = lsa.fit_transform(X)\n",
    "\n",
    "    variance_explained=svd.explained_variance_ratio_\n",
    "    total_variance = variance_explained.sum()\n",
    "    print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "    #Looking at what sorts of paragraphs our solution considers similar, for the first five identified topics\n",
    "    paras_by_component=pd.DataFrame(X_lsa)\n",
    "    print('output shape:' + str(paras_by_component.shape))\n",
    "    return paras_by_component\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 58.96173068948395\n",
      "output shape:(8143, 300)\n"
     ]
    }
   ],
   "source": [
    "Y = small_combined_df['author']\n",
    "X = svd_converter(300, small_combined_df.drop(['author','title','paragraph'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.8115408225905464\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.87      0.82      0.84       382\n",
      "     Dickens       0.77      0.83      0.80       455\n",
      "   Stevenson       0.83      0.86      0.84       430\n",
      "       Twain       0.79      0.72      0.75       362\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1629\n",
      "   macro avg       0.81      0.81      0.81      1629\n",
      "weighted avg       0.81      0.81      0.81      1629\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.80428135 0.79510703 0.77230769 0.70769231 0.77846154]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=200, random_state=23)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('RFC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, rfc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 50.162294031414575\n",
      "output shape:(44898, 300)\n"
     ]
    }
   ],
   "source": [
    "Y = big_combined_df['author']\n",
    "X = svd_converter(300, big_combined_df.drop(['author','title','paragraph'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.6606904231625835\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.81      0.75      0.78      2100\n",
      "     Dickens       0.58      0.72      0.64      2869\n",
      "   Stevenson       0.77      0.28      0.41      1399\n",
      "       Twain       0.64      0.73      0.68      2612\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      8980\n",
      "   macro avg       0.70      0.62      0.63      8980\n",
      "weighted avg       0.68      0.66      0.65      8980\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.58931553 0.59599332 0.6174833  0.61358575 0.61928651]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=200, random_state=23)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('RFC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, rfc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well.  That made it _worse_.  Maybe 300 features & 50% variance is insufficient.  Let's try 600 and see what happens with the smaller sample.\n",
    "\n",
    "* SVD = 300, model score = 81.15%\n",
    "* SVD = 600, model score = 80.48%\n",
    "* SVD = 900, model score = 79.68%\n",
    "\n",
    "Okay, duly noted: increasing the SVD makes the score worse.  Let's try dropping it.\n",
    "\n",
    "* SVD = 150, model score = 81.35%\n",
    "* SVD = 100, model score = 81.77%\n",
    "* SVD = 50, model score = 81.95%, 82.26%\n",
    "* SVD = 25, model score = 81.4%\n",
    "* SVD = 40, model score = 81.03%\n",
    "* SVD = 15, model score = 79.87%\n",
    "* SVD = 60, model score = 82.08%, 81.89%, 82.01%\n",
    "* SVD = 70, model score = 81.65%\n",
    "* SVD = 65, model score = 81.89%\n",
    "* SVD = 55, model score = 81.4%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 25.117792645466647\n",
      "output shape:(8143, 60)\n"
     ]
    }
   ],
   "source": [
    "Y = small_combined_df['author']\n",
    "X = svd_converter(60, small_combined_df.drop(['author','title','paragraph'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.8201350521792511\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.87      0.82      0.84       382\n",
      "     Dickens       0.80      0.82      0.81       455\n",
      "   Stevenson       0.84      0.87      0.85       430\n",
      "       Twain       0.77      0.76      0.77       362\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1629\n",
      "   macro avg       0.82      0.82      0.82      1629\n",
      "weighted avg       0.82      0.82      0.82      1629\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.81345566 0.75229358 0.77846154 0.74461538 0.78153846]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=200, random_state=23)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('RFC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, rfc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 19.826417881455622\n",
      "output shape:(44898, 50)\n"
     ]
    }
   ],
   "source": [
    "Y = big_combined_df['author']\n",
    "X = svd_converter(50, big_combined_df.drop(['author','title','paragraph'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC results:\n",
      " \n",
      "Model score:\n",
      "0.6506681514476614\n",
      " \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.75      0.75      0.75      2100\n",
      "     Dickens       0.60      0.66      0.63      2869\n",
      "   Stevenson       0.68      0.34      0.45      1399\n",
      "       Twain       0.63      0.72      0.67      2612\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      8980\n",
      "   macro avg       0.66      0.62      0.63      8980\n",
      "weighted avg       0.66      0.65      0.64      8980\n",
      "\n",
      " \n",
      "Model cross-valuation:\n",
      "[0.58987201 0.5998887  0.60244989 0.57349666 0.59253066]\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=200, random_state=23)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('RFC results:')\n",
    "print(' ')\n",
    "accuracy_report(X_test, y_test, rfc, 1)\n",
    "os.system('say \"all done.\"'); print('\\a')  # this is going to take a while, let me know when it's done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odd.  SVD seems to make things worse, in every test case.  Not what I was expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "# for reference, a full list of the urls used in this project\n",
    "\n",
    "prideandprejudice_Austen = get_paragraphs('http://www.gutenberg.org/files/1342/1342-0.txt')\n",
    "frankenstein_Shelley = get_paragraphs('http://www.gutenberg.org/files/84/84-0.txt')\n",
    "taleoftwocities_Dickens = get_paragraphs('http://www.gutenberg.org/files/98/98-0.txt')\n",
    "mobydick_Melville = get_paragraphs('http://www.gutenberg.org/files/2701/2701-0.txt')\n",
    "modestproposal_Swift = get_paragraphs('http://www.gutenberg.org/cache/epub/1080/pg1080.txt')\n",
    "print('5')\n",
    "importanceofbeingearnest_Wilde = get_paragraphs('http://www.gutenberg.org/cache/epub/844/pg844.txt')\n",
    "aliceinwonderland_Carroll = get_paragraphs('http://www.gutenberg.org/files/11/11-0.txt')\n",
    "dollshouse_Ibsen = get_paragraphs('http://www.gutenberg.org/cache/epub/2542/pg2542.txt')\n",
    "sherlockholmes_Doyle = get_paragraphs('http://www.gutenberg.org/cache/epub/1661/pg1661.txt')\n",
    "heartofdarkness_Conrad = get_paragraphs('http://www.gutenberg.org/files/219/219-0.txt')\n",
    "print('10')\n",
    "warandpeace_Tolstoy = get_paragraphs('http://www.gutenberg.org/files/2600/2600-0.txt')\n",
    "theawakening_Chopin = get_paragraphs('http://www.gutenberg.org/files/160/160-0.txt')\n",
    "dracula_Stoker = get_paragraphs('http://www.gutenberg.org/cache/epub/345/pg345.txt')\n",
    "crimeandpunishment_Dostoevsky = get_paragraphs('http://www.gutenberg.org/files/2554/2554-0.txt')\n",
    "drjekyllmrhyde_Stevenson = get_paragraphs('http://www.gutenberg.org/files/43/43-0.txt')\n",
    "print('15')\n",
    "iliad_Homer = get_texts('http://www.gutenberg.org/cache/epub/6130/pg6130.txt')\n",
    "greatexpectations_Dickens = get_paragraphs('http://www.gutenberg.org/files/1400/1400-0.txt')\n",
    "metamorphosis_Kafka = get_paragraphs('http://www.gutenberg.org/cache/epub/5200/pg5200.txt')\n",
    "huckleberryfinn_Twain = get_paragraphs('http://www.gutenberg.org/files/76/76-0.txt')\n",
    "disappearanceofkimballwebb_Wright = get_paragraphs('http://www.gutenberg.org/files/59060/59060-0.txt')\n",
    "\n",
    "os.system('say \"all done.\"'); print('\\a')  # this could take a while, let me know when it's done\n",
    "\n",
    "#xxx = get_paragraphs('')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
