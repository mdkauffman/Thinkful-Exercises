{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "import math\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "#from nltk.corpus import gutenberg, stopwords\n",
    "#from collections import Counter\n",
    "#import nltk\n",
    "#nltk.download('gutenberg')\n",
    "\n",
    "#from spacy.lang.en import English\n",
    "\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"scipy\",\n",
    "    message=\"^internal gelsd\"\n",
    ")\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import neighbors\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from nltk.tokenize import BlanklineTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import urllib.request\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics\n",
    "from itertools import cycle\n",
    "\n",
    "import pydotplus\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "# Set seed.\n",
    "random.seed(a=100)\n",
    "\n",
    "# Create our default list.\n",
    "short_list = list(random.sample(range(1000000), 10))\n",
    "long_list = list(random.sample(range(1000000), 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(child, parent, array):\n",
    "    array[child], array[parent] = array[parent], array[child]\n",
    "\n",
    "def heapify(end, x, array):\n",
    "    \n",
    "    # identify the two children of 'x'\n",
    "    left_child = 2 * x + 1\n",
    "    right_child = 2 * (x + 1)\n",
    "    \n",
    "    # set a max_value 'title' to allow us to keep track of which index has a higher value than the other two.\n",
    "    max_value = x\n",
    "    \n",
    "    # if the left hand child's index is less than the length of the array (a failsafe)\n",
    "    # and its value is greater than that of its parent, set it as the max_value\n",
    "    if left_child < end and array[max_value] < array[left_child]:\n",
    "        max_value = left_child\n",
    "        \n",
    "    # do the same for the right child, comparing its value to whichever value currently holds the max_value title\n",
    "    if right_child < end and array[max_value] < array[right_child]:\n",
    "        max_value = right_child\n",
    "    \n",
    "    # if the parent is no longer the max_value, swap it and whichever *is* the max_value\n",
    "    if max_value != x:\n",
    "        swap(x, max_value, array)\n",
    "        # and then double-check that the swap produced the correct result by running the function\n",
    "        # recursively on the same index number\n",
    "        heapify(end, max_value, array)\n",
    "\n",
    "        \n",
    "def heap_sort(array):\n",
    "    \n",
    "    # set a variable as the length of the array, so that the function knows where to start and end\n",
    "    end = len(array)\n",
    "\n",
    "    # set the starting variable for the heap-sort as the latest branch point in the array\n",
    "    start = end // 2 - 1\n",
    "    \n",
    "    # start at the last branch point and work our way up towards the root, heapifying as we go\n",
    "    for n in range(start, -1, -1):\n",
    "        heapify(end, n, array)\n",
    "        \n",
    "    # go through from the end to the beginning and move the root, at index 0, \n",
    "    # (which should be the largest so-far-unsorted value) to the end of the currently unsorted section, \n",
    "    # then re-heapify the remaining list; repeat ad-nauseum until we've gone through the whole list.\n",
    "    for i in range(end-1, 0, -1):\n",
    "        swap(i, 0, array)\n",
    "        heapify(i, 0, array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7.796287536621094e-05 seconds ---\n",
      "[803333, 821597, 705059, 475321, 457878, 120112, 409468, 387862, 229489, 924390]\n"
     ]
    }
   ],
   "source": [
    "# Create our default list.\n",
    "short_list = list(random.sample(range(1000000), 10))\n",
    "\n",
    "# Start the timer.\n",
    "start_time = time.time()\n",
    "heap_sort(short_list)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(short_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.1420907974243164 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Create our default list.\n",
    "long_list = list(random.sample(range(1000000), 10000))\n",
    "\n",
    "# Start the timer.\n",
    "start_time = time.time()\n",
    "heap_sort(long_list)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#print(long_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
